{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.8.0+cpu CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "from utils.google_utils import gdrive_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Github\\Tesi_Francesca\\content\\yolov5\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in grapes-detection-2 to createml: 100% [8663577 / 8663577] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to grapes-detection-2 in createml:: 100%|██████████| 122/122 [00:00<00:00, 393.27it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd content/yolov5\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"wt2KhAtPzHCHqMJG7RHK\")\n",
    "project = rf.workspace(\"grappes-detection\").project(\"grapes-detection-g36ar\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"createml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Github\\Tesi_Francesca\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mCommand 'git rev-list main..origin/master --count' returned non-zero exit status 128.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: No labels found in content\\yolov5\\grapes-detection-2\\train.cache. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 7.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: ambiguous argument 'main..origin/master': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "YOLOv5 a6cd8bc torch 1.8.0+cpu CPU\n",
      "\n",
      "Namespace(weights=\"''\", cfg='content/yolov5/models/custom_yolov5s.yaml', data='content/yolov5/grapes-detection-2/data.yaml', hyp='data/hyp.scratch.yaml', epochs=50, batch_size=16, img_size=[416, 416], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=True, image_weights=False, device='', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, log_imgs=16, log_artifacts=False, workers=8, project='runs/train', entity=None, name='yolov5s_results', exist_ok=False, quad=False, linear_lr=False, world_size=1, global_rank=-1, save_dir='runs\\\\train\\\\yolov5s_results5', total_batch_size=16)\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
      "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "Overriding model.yaml nc={'num_classes': None} with nc=6\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     29667  models.yolo.Detect                      [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7268579 parameters, 7268579 gradients, 17.0 GFLOPS\n",
      "\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\n",
      "Scanning images:   0%|          | 0/93 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 1 missing, 0 empty, 0 corrupted:   1%|          | 1/93 [00:00<00:19,  4.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 8 missing, 0 empty, 0 corrupted:   9%|▊         | 8/93 [00:00<00:13,  6.46it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 14 missing, 0 empty, 0 corrupted:  15%|█▌        | 14/93 [00:00<00:08,  8.83it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 24 missing, 0 empty, 0 corrupted:  26%|██▌       | 24/93 [00:00<00:05, 12.14it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 35 missing, 0 empty, 0 corrupted:  38%|███▊      | 35/93 [00:00<00:03, 16.46it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 43 missing, 0 empty, 0 corrupted:  46%|████▌     | 43/93 [00:00<00:02, 21.51it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 53 missing, 0 empty, 0 corrupted:  57%|█████▋    | 53/93 [00:00<00:01, 27.99it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 62 missing, 0 empty, 0 corrupted:  67%|██████▋   | 62/93 [00:00<00:00, 35.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 72 missing, 0 empty, 0 corrupted:  77%|███████▋  | 72/93 [00:01<00:00, 43.23it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 84 missing, 0 empty, 0 corrupted:  90%|█████████ | 84/93 [00:01<00:00, 53.00it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'content\\yolov5\\grapes-detection-2\\train' for images and labels... 0 found, 93 missing, 0 empty, 0 corrupted: 100%|██████████| 93/93 [00:01<00:00, 74.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: content\\yolov5\\grapes-detection-2\\train.cache\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Github\\Tesi_Francesca\\train.py\", line 531, in <module>\n",
      "    train(hyp, opt, device, tb_writer, wandb)\n",
      "  File \"C:\\Github\\Tesi_Francesca\\train.py\", line 185, in train\n",
      "    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,\n",
      "  File \"C:\\Github\\Tesi_Francesca\\utils\\datasets.py\", line 63, in create_dataloader\n",
      "    dataset = LoadImagesAndLabels(path, imgsz, batch_size,\n",
      "  File \"C:\\Github\\Tesi_Francesca\\utils\\datasets.py\", line 390, in __init__\n",
      "    assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {help_url}'\n",
      "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo labels in content\\yolov5\\grapes-detection-2\\train.cache. Can not train without labels. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%cd C:/Github/Tesi_Francesca/\n",
    "\n",
    "!python train.py --img 416 --batch 16 --epochs 50 --data content/yolov5/grapes-detection-2/data.yaml --cfg content/yolov5/models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
